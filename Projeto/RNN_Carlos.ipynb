{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22f95ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64b9576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./df_test.csv')\n",
    "df = df.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55026980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105568</th>\n",
       "      <td>115764</td>\n",
       "      <td>I think it looks great</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160984</th>\n",
       "      <td>176492</td>\n",
       "      <td>Shit out to my little hommies who's parents ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35344</th>\n",
       "      <td>38691</td>\n",
       "      <td>TIL screwing people over is just fine as long ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117576</th>\n",
       "      <td>128900</td>\n",
       "      <td>I love you, as a feminist with ASD words are v...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65508</th>\n",
       "      <td>71829</td>\n",
       "      <td>thanks... I've added both these to my growing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189697</th>\n",
       "      <td>208106</td>\n",
       "      <td>I can shit on [NAME] and [NAME] as well if you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94385</th>\n",
       "      <td>103479</td>\n",
       "      <td>Amazing. It looks like a penis and a vagina at...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94457</th>\n",
       "      <td>103562</td>\n",
       "      <td>I love it! Guy in front can steer, can't prope...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72675</th>\n",
       "      <td>79653</td>\n",
       "      <td>[NAME] seems like such a quality guy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186492</th>\n",
       "      <td>204574</td>\n",
       "      <td>I tried to quit smoking it only lasted 1 month...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  \\\n",
       "105568      115764                             I think it looks great   \n",
       "160984      176492  Shit out to my little hommies who's parents ma...   \n",
       "35344        38691  TIL screwing people over is just fine as long ...   \n",
       "117576      128900  I love you, as a feminist with ASD words are v...   \n",
       "65508        71829  thanks... I've added both these to my growing ...   \n",
       "...            ...                                                ...   \n",
       "189697      208106  I can shit on [NAME] and [NAME] as well if you...   \n",
       "94385       103479  Amazing. It looks like a penis and a vagina at...   \n",
       "94457       103562  I love it! Guy in front can steer, can't prope...   \n",
       "72675        79653               [NAME] seems like such a quality guy   \n",
       "186492      204574  I tried to quit smoking it only lasted 1 month...   \n",
       "\n",
       "        positive  neutral  negative  \n",
       "105568         1        0         0  \n",
       "160984         0        0         1  \n",
       "35344          0        1         0  \n",
       "117576         1        0         0  \n",
       "65508          1        0         0  \n",
       "...          ...      ...       ...  \n",
       "189697         0        1         0  \n",
       "94385          1        0         0  \n",
       "94457          1        0         0  \n",
       "72675          1        0         0  \n",
       "186492         0        0         1  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113333cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def __remove_punctuation(text):\n",
    "    \"\"\"\n",
    "        remove punctuation from text and lower case it\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    punctuations = string.punctuation\n",
    "    punctuations += '“'\n",
    "    punctuations += '’'\n",
    "    punctuations += '”'\n",
    "    punctuations += '’'\n",
    "    punctuations += ' — '\n",
    "    punctuations += 'â€œ'\n",
    "    punctuations += 'â€¦'\n",
    "    punctuations += 'â€'\n",
    "    punctuations += '€™'\n",
    "    punctuations += '€'\n",
    "    punctuations += '™'\n",
    "    punctuations += '¦'\n",
    "    punctuations += 'œ'\n",
    "    punctuations += 'Â'\n",
    "    punctuations += 'Ã'\n",
    "    punctuations += '— '\n",
    "    punctuations += '¶'\n",
    "    punctuations += '§'\n",
    "    punctuations += '£'\n",
    "    punctuations += '©'\n",
    "    punctuations += 'ª'\n",
    "    punctuations += '³'\n",
    "\n",
    "    # text = emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, ' ') \n",
    "        #text = text.replace('donald', 'trump')\n",
    "        #text = text.replace('clinton', 'hillary')\n",
    "    return text.lower() # lower case\n",
    "\n",
    "def __remove_numbers(text):\n",
    "    \"\"\"\n",
    "        remove number from text\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    words_only = ''.join([i for i in text if not i.isdigit()])\n",
    "    return words_only\n",
    "\n",
    "# def __remove_stopwords(text):\n",
    "#     \"\"\"\n",
    "#         remove stop words from text\n",
    "#     \"\"\"\n",
    "#     text = str(text)\n",
    "\n",
    "#     # stop_words = stopwords.words('english')\n",
    "#     #stop_words += stopwords.words('portuguese')\n",
    "#     stop_words.append('mr')\n",
    "#     stop_words = set(stop_words)\n",
    "\n",
    "#     tokenized = word_tokenize(text)\n",
    "#     without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "#     return without_stopwords\n",
    "\n",
    "def __lemmatize(text):\n",
    "    \"\"\"\n",
    "        lemmatize text\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    lemmatized_string = \" \".join(lemmatized)\n",
    "    return lemmatized_string\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "        process the data\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "        \n",
    "    df_['text'] = df_['text'].apply(__remove_punctuation)\n",
    "\n",
    "    df_['text'] = df_['text'].apply(__remove_numbers)\n",
    "\n",
    "    # df_['text'] = df_['text'].apply(__remove_stopwords)\n",
    "\n",
    "    # df_['text'] = df_['text'].apply(__lemmatize)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c91e2491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences = process_data(df)\n",
    "cleaned_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6558ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105568                               i think it looks great\n",
       "160984    shit out to my little hommies who s parents ma...\n",
       "35344     til screwing people over is just fine as long ...\n",
       "117576    i love you  as a feminist with asd words are v...\n",
       "65508     thanks    i ve added both these to my growing ...\n",
       "                                ...                        \n",
       "189697    i can shit on  name  and  name  as well if you...\n",
       "94385     amazing  it looks like a penis and a vagina at...\n",
       "94457     i love it  guy in front can steer  can t prope...\n",
       "72675                   name  seems like such a quality guy\n",
       "186492    i tried to quit smoking it only lasted  month ...\n",
       "Name: text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510941d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "X = count_vectorizer.fit_transform(cleaned_sentences['text'])\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baf05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "### Let's create some mock data\n",
    "def get_mock_up_data():\n",
    "\n",
    "\n",
    "    ### Let's tokenize the vocabulary \n",
    "    tk = Tokenizer(cleaned_sentences['text'])\n",
    "    tk.fit_on_texts(cleaned_sentences['text'])\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "    X_token = tk.texts_to_sequences(cleaned_sentences['text'])\n",
    "\n",
    "    ### Pad the inputs\n",
    "    X_pad = pad_sequences(X_token, dtype='float32', padding='post')\n",
    "    \n",
    "    return X_pad, y, vocab_size\n",
    "\n",
    "X_pad, y, vocab_size = get_mock_up_data()\n",
    "print(\"X_pad.shape\", X_pad.shape)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71547b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "### Let's create some mock data\n",
    "def get_mock_up_data(X):\n",
    "\n",
    "\n",
    "    ### Let's tokenize the vocabulary \n",
    "    tk = Tokenizer(X)\n",
    "    tk.fit_on_texts(X)\n",
    "    vocab_size = len(tk.word_index)\n",
    "    print(f'There are {vocab_size} different words in your corpus')\n",
    "    X_token = tk.texts_to_sequences(X)\n",
    "\n",
    "    ### Pad the inputs\n",
    "    X_pad = pad_sequences(X_token, dtype='float32', padding='post')\n",
    "    \n",
    "    return X_pad, vocab_size\n",
    "\n",
    "X_pad, vocab_size = get_mock_up_data()\n",
    "print(\"X_pad.shape\", X_pad.shape)\n",
    "X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fa399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[['positive', 'negative', 'neutral']], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2c9261",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Normalization\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense, SimpleRNN, Flatten\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e5381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pad, vocab_size = get_mock_up_data(X_train)\n",
    "X_test_pad, vocab_size = get_mock_up_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc2054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
