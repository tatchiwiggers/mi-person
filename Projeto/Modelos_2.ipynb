{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "22f95ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "64b9576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./df_test.csv')\n",
    "#df = df.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3aa1b759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 5)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr_samples = 50000\n",
    "df0 = df[df['positive'] == 1].sample(nr_samples)\n",
    "df1 = df[df['negative'] == 1].sample(nr_samples)\n",
    "df2 = df[df['neutral'] == 1].sample(nr_samples)\n",
    "df = pd.concat([df0,df1,df2])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "113333cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def __remove_punctuation(text):\n",
    "    \"\"\"\n",
    "        remove punctuation from text and lower case it\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    punctuations = string.punctuation\n",
    "    punctuations += '“'\n",
    "    punctuations += '’'\n",
    "    punctuations += '”'\n",
    "    punctuations += '’'\n",
    "    punctuations += ' — '\n",
    "    punctuations += 'â€œ'\n",
    "    punctuations += 'â€¦'\n",
    "    punctuations += 'â€'\n",
    "    punctuations += '€™'\n",
    "    punctuations += '€'\n",
    "    punctuations += '™'\n",
    "    punctuations += '¦'\n",
    "    punctuations += 'œ'\n",
    "    punctuations += 'Â'\n",
    "    punctuations += 'Ã'\n",
    "    punctuations += '— '\n",
    "    punctuations += '¶'\n",
    "    punctuations += '§'\n",
    "    punctuations += '£'\n",
    "    punctuations += '©'\n",
    "    punctuations += 'ª'\n",
    "    punctuations += '³'\n",
    "\n",
    "    # text = emoji.get_emoji_regexp().sub(u'', text)\n",
    "\n",
    "    for punctuation in punctuations:\n",
    "        text = text.replace(punctuation, ' ') \n",
    "        #text = text.replace('donald', 'trump')\n",
    "        #text = text.replace('clinton', 'hillary')\n",
    "    return text.lower() # lower case\n",
    "\n",
    "def __remove_numbers(text):\n",
    "    \"\"\"\n",
    "        remove number from text\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "\n",
    "    words_only = ''.join([i for i in text if not i.isdigit()])\n",
    "    return words_only.strip()\n",
    "\n",
    "# def __remove_stopwords(text):\n",
    "#     \"\"\"\n",
    "#         remove stop words from text\n",
    "#     \"\"\"\n",
    "#     text = str(text)\n",
    "\n",
    "#     # stop_words = stopwords.words('english')\n",
    "#     #stop_words += stopwords.words('portuguese')\n",
    "#     stop_words.append('mr')\n",
    "#     stop_words = set(stop_words)\n",
    "\n",
    "#     tokenized = word_tokenize(text)\n",
    "#     without_stopwords = [word for word in tokenized if not word in stop_words]\n",
    "#     return without_stopwords\n",
    "\n",
    "def __lemmatize(text):\n",
    "    \"\"\"\n",
    "        lemmatize text\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    lemmatized_string = \" \".join(lemmatized)\n",
    "    return lemmatized_string\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"\n",
    "        process the data\n",
    "    \"\"\"\n",
    "\n",
    "    df_ = df.copy()\n",
    "        \n",
    "    df_['text'] = df_['text'].apply(__remove_punctuation)\n",
    "\n",
    "    df_['text'] = df_['text'].apply(__remove_numbers)\n",
    "\n",
    "    # df_['text'] = df_['text'].apply(__remove_stopwords)\n",
    "\n",
    "    # df_['text'] = df_['text'].apply(__lemmatize)\n",
    "    \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c91e2491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 5)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences = process_data(df)\n",
    "cleaned_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "30f370c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150000, 5)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences.dropna(inplace=True)\n",
    "cleaned_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6558ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76433     well  my upcoming adverts are going to be inte...\n",
       "67561                                                my man\n",
       "50063                                      great job thanks\n",
       "75636     i m glad you had a great time here  wishing yo...\n",
       "37226     we can hammer out the details later      don t...\n",
       "                                ...                        \n",
       "122274                       and yet you have so much karma\n",
       "174771    suddenly  dorion will fleece another gm of the...\n",
       "90525     no child should go without needed medical care...\n",
       "138418    yeah  the only time i ever parked like that wa...\n",
       "91123     if we shoot by accident we don t keep feeding ...\n",
       "Name: text, Length: 150000, dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "19dff028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    150000.000000\n",
       "mean         13.332967\n",
       "std           6.871415\n",
       "min           0.000000\n",
       "25%           8.000000\n",
       "50%          13.000000\n",
       "75%          19.000000\n",
       "max          35.000000\n",
       "Name: num_words, dtype: float64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences[\"num_words\"] = cleaned_sentences[\"text\"].apply(lambda x:len(str(x).split()))\n",
    "cleaned_sentences[\"num_words\"].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f92c4856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>num_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15432</th>\n",
       "      <td>16910</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109483</th>\n",
       "      <td>120041</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60933</th>\n",
       "      <td>66808</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100173</th>\n",
       "      <td>109849</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18273</th>\n",
       "      <td>20020</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81407</th>\n",
       "      <td>89246</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 text  positive  neutral  negative  num_words\n",
       "15432        16910              0        1         0          0\n",
       "109483      120041              0        1         0          0\n",
       "60933        66808              0        1         0          0\n",
       "100173      109849              0        1         0          0\n",
       "18273        20020              0        1         0          0\n",
       "81407        89246              0        1         0          0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sentences[cleaned_sentences[\"num_words\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "15a73742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "### Let's create some mock data\n",
    "max_len = 64\n",
    "def get_mock_up_data(tk, X):\n",
    "    X_token = tk.texts_to_sequences(X)\n",
    "\n",
    "    ### Pad the inputs\n",
    "    X_pad = pad_sequences(X_token, maxlen=max_len, dtype='float32', padding='post')\n",
    "    \n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0fa399d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_sentences['text'], df[['positive', 'negative', 'neutral']], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bf2c9261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, Embedding, LSTM \n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "39069842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29979 different words in your corpus\n"
     ]
    }
   ],
   "source": [
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(cleaned_sentences['text'])\n",
    "vocab_size = len(tk.word_index)+1\n",
    "print(f'There are {vocab_size} different words in your corpus')\n",
    "\n",
    "X_train_pad = get_mock_up_data(tk, X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b9de6702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105000, 64)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a39338c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pad = get_mock_up_data(tk, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d6e2195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "dfdefe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 64, 32)            959328    \n",
      "                                                                 \n",
      " lstm_32 (LSTM)              (None, 64, 32)            8320      \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 20)                4240      \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 973,631\n",
      "Trainable params: 973,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Size of your embedding space = size of the vector representing each word\n",
    "embedding_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size, # 16 +1 for the 0 padding\n",
    "    input_length=max_len, # Max_sentence_length (optional, for model summary)\n",
    "    output_dim=embedding_size, # 100\n",
    "    mask_zero=True, # Built-in masking layer :)\n",
    "))\n",
    "\n",
    "#model.add(LSTM(32))\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))\n",
    "#model.add(LSTM(32, return_sequences=True))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "#model.add(Dense(20, activation='relu'))\n",
    "#model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e456fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "learning_rate = 1e-3\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='rmsprop',\n",
    "              #optimizer=opt,\n",
    "             metrics=['accuracy',Precision(),Recall()]) # Use `rmsprop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e570d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#monitor=\"accuracy\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a0b046ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor=\"val_loss\", patience=6, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fe1c1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3282/3282 [==============================] - 622s 187ms/step - loss: 0.9342 - accuracy: 0.5478 - precision_19: 0.6686 - recall_19: 0.3249 - val_loss: 0.8747 - val_accuracy: 0.6006 - val_precision_19: 0.6615 - val_recall_19: 0.4850\n",
      "Epoch 2/1000\n",
      "3282/3282 [==============================] - 475s 145ms/step - loss: 0.8522 - accuracy: 0.6129 - precision_19: 0.6829 - recall_19: 0.4813 - val_loss: 0.8619 - val_accuracy: 0.6085 - val_precision_19: 0.6810 - val_recall_19: 0.4702\n",
      "Epoch 3/1000\n",
      "3282/3282 [==============================] - 497s 151ms/step - loss: 0.8253 - accuracy: 0.6323 - precision_19: 0.6978 - recall_19: 0.5133 - val_loss: 0.8503 - val_accuracy: 0.6096 - val_precision_19: 0.6786 - val_recall_19: 0.4804\n",
      "Epoch 4/1000\n",
      "3282/3282 [==============================] - 481s 146ms/step - loss: 0.8023 - accuracy: 0.6458 - precision_19: 0.7062 - recall_19: 0.5386 - val_loss: 0.8549 - val_accuracy: 0.6084 - val_precision_19: 0.6709 - val_recall_19: 0.4934\n",
      "Epoch 5/1000\n",
      "3282/3282 [==============================] - 503s 153ms/step - loss: 0.7829 - accuracy: 0.6566 - precision_19: 0.7156 - recall_19: 0.5595 - val_loss: 0.8612 - val_accuracy: 0.6082 - val_precision_19: 0.6619 - val_recall_19: 0.5029\n",
      "Epoch 6/1000\n",
      "3282/3282 [==============================] - 498s 152ms/step - loss: 0.7665 - accuracy: 0.6681 - precision_19: 0.7232 - recall_19: 0.5767 - val_loss: 0.8640 - val_accuracy: 0.6053 - val_precision_19: 0.6617 - val_recall_19: 0.5083\n",
      "Epoch 7/1000\n",
      "3282/3282 [==============================] - 484s 147ms/step - loss: 0.7524 - accuracy: 0.6764 - precision_19: 0.7306 - recall_19: 0.5932 - val_loss: 0.8681 - val_accuracy: 0.6086 - val_precision_19: 0.6655 - val_recall_19: 0.5007\n",
      "Epoch 8/1000\n",
      "3282/3282 [==============================] - 500s 152ms/step - loss: 0.7411 - accuracy: 0.6836 - precision_19: 0.7338 - recall_19: 0.6067 - val_loss: 0.8914 - val_accuracy: 0.6004 - val_precision_19: 0.6469 - val_recall_19: 0.5160\n",
      "Epoch 9/1000\n",
      "3282/3282 [==============================] - 487s 148ms/step - loss: 0.7309 - accuracy: 0.6897 - precision_19: 0.7383 - recall_19: 0.6165 - val_loss: 0.9211 - val_accuracy: 0.6006 - val_precision_19: 0.6364 - val_recall_19: 0.5351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5419917370>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_pad, y_train, \n",
    "          epochs=1000, \n",
    "          batch_size=32, \n",
    "          verbose=1, \n",
    "          callbacks = [es],\n",
    "          validation_data=(X_test_pad,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a9b6d",
   "metadata": {},
   "source": [
    "model_3 = Sequential()\n",
    "#model_3.add(layers.LSTM(units=40, input_shape=(12575,1), activation='tanh', return_sequences=True))\n",
    "#model_3.add(layers.LSTM(units=20, activation='tanh', return_sequences=False))\n",
    "model_3.add(Dense(20, activation=\"relu\"))\n",
    "model_3.add(Dense(20, activation=\"relu\"))\n",
    "model_3.add(Dense(20, activation=\"relu\"))\n",
    "model_3.add(Dense(10, activation=\"relu\"))\n",
    "model_3.add(Dense(3, activation='softmax'))\n",
    "model_3.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
